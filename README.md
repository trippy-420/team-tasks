# Team Tasks â€” Multi-Agent Pipeline Coordination

A Python CLI tool for coordinating multi-agent development workflows through shared JSON task files. Designed for use with [OpenClaw](https://github.com/openclaw/openclaw) and AI agent orchestration systems.

## Features

Three coordination modes for different workflows:

| Mode | Description | Use Case |
|------|-------------|----------|
| **Linear** | Sequential pipeline with auto-advance | Bug fixes, simple features, step-by-step workflows |
| **DAG** | Dependency graph with parallel dispatch | Large features, spec-driven dev, complex dependencies |
| **Debate** | Multi-agent position + cross-review | Code reviews, architecture decisions, competing hypotheses |

## Requirements

- Python 3.12+ (stdlib only, no external dependencies)
- Data stored as JSON in `/home/ubuntu/clawd/data/team-tasks/` (override with `TEAM_TASKS_DIR` env var)

## Installation

```bash
# Clone the repo
git clone https://github.com/win4r/team-tasks.git

# No pip install needed â€” it's a standalone script
python3 team-tasks/scripts/task_manager.py --help
```

For OpenClaw skill integration, copy to your skills directory:
```bash
cp -r team-tasks/ /path/to/clawd/skills/team-tasks/
```

## Quick Start

### Mode A: Linear Pipeline

A sequential pipeline where agents execute one after another in order.

```bash
TM="python3 scripts/task_manager.py"

# 1. Create project with pipeline order
$TM init my-api -g "Build REST API with tests and docs" \
  -p "code-agent,test-agent,docs-agent,monitor-bot"

# 2. Assign tasks to each stage
$TM assign my-api code-agent "Implement Flask REST API: GET/POST/DELETE /items"
$TM assign my-api test-agent "Write pytest tests, target 90%+ coverage"
$TM assign my-api docs-agent "Write README with API docs and examples"
$TM assign my-api monitor-bot "Security audit and deployment readiness check"

# 3. Check what's next
$TM next my-api
# â–¶ï¸  Next stage: code-agent

# 4. Dispatch â†’ work â†’ save result â†’ mark done
$TM update my-api code-agent in-progress
# ... agent does work ...
$TM result my-api code-agent "Created app.py with 3 endpoints"
$TM update my-api code-agent done
# â–¶ï¸  Next: test-agent  (auto-advance!)

# 5. Check progress anytime
$TM status my-api
```

**Output example:**
```
ğŸ“‹ Project: my-api
ğŸ¯ Goal: Build REST API with tests and docs
ğŸ“Š Status: active  |  Mode: linear
â–¶ï¸  Current: test-agent

  âœ… code-agent: done
     Task: Implement Flask REST API
     Output: Created app.py with 3 endpoints
  ğŸ”„ test-agent: in-progress
     Task: Write pytest tests, target 90%+ coverage
  â¬œ docs-agent: pending
  â¬œ monitor-bot: pending

  Progress: [â–ˆâ–ˆâ–‘â–‘] 2/4
```

### Mode B: DAG (Dependency Graph)

Tasks declare dependencies and run in parallel when deps are met.

```bash
TM="python3 scripts/task_manager.py"

# 1. Create DAG project
$TM init my-feature -m dag -g "Build search feature with parallel workstreams"

# 2. Add tasks with dependencies
$TM add my-feature design     -a docs-agent  --desc "Write API spec"
$TM add my-feature scaffold   -a code-agent  --desc "Create project skeleton"
$TM add my-feature implement  -a code-agent  -d "design,scaffold" --desc "Implement API"
$TM add my-feature write-tests -a test-agent -d "design"          --desc "Write test cases from spec"
$TM add my-feature run-tests  -a test-agent  -d "implement,write-tests" --desc "Run all tests"
$TM add my-feature write-docs -a docs-agent  -d "implement"             --desc "Write final docs"
$TM add my-feature review     -a monitor-bot -d "run-tests,write-docs"  --desc "Final review"

# 3. Visualize the DAG
$TM graph my-feature
```

**Graph output:**
```
ğŸ“‹ my-feature â€” DAG Graph

â”œâ”€ â¬œ design [docs-agent]
â”‚  â”œâ”€ â¬œ implement [code-agent]
â”‚  â”‚  â”œâ”€ â¬œ run-tests [test-agent]
â”‚  â”‚  â”‚  â””â”€ â¬œ review [monitor-bot]
â”‚  â”‚  â””â”€ â¬œ write-docs [docs-agent]
â”‚  â””â”€ â¬œ write-tests [test-agent]
â””â”€ â¬œ scaffold [code-agent]
   â””â”€ â¬œ implement (â†‘ see above)

  Progress: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0/7
```

```bash
# 4. Get ready tasks (parallel dispatch!)
$TM ready my-feature
# ğŸŸ¢ Ready to dispatch (2 tasks):
#   ğŸ“Œ design â†’ agent: docs-agent
#   ğŸ“Œ scaffold â†’ agent: code-agent

# 5. Dispatch both in parallel, then mark done
$TM update my-feature design done
# ğŸŸ¢ Unblocked: write-tests  â† auto-detected!

$TM update my-feature scaffold done
# ğŸŸ¢ Unblocked: implement

# 6. Continue until all complete
$TM ready my-feature  # Shows newly unblocked tasks
```

**Key DAG features:**
- `ready` returns ALL tasks whose deps are satisfied â€” dispatch them simultaneously
- `ready --json` includes `depOutputs` â€” previous stage results to pass to agents
- Automatic unblock notifications when a task completes
- Cycle detection on `add` â€” rejects tasks that would create circular dependencies
- Partial failure: unrelated branches continue; only downstream tasks block

### Mode C: Debate (Multi-Agent Deliberation)

Send the same question to multiple agents, collect positions, cross-review, and synthesize.

```bash
TM="python3 scripts/task_manager.py"

# 1. Create debate project
$TM init security-review --mode debate \
  -g "Review auth module for security vulnerabilities"

# 2. Add debaters with roles/perspectives
$TM add-debater security-review code-agent  --role "security expert focused on injection attacks"
$TM add-debater security-review test-agent  --role "QA engineer focused on edge cases"
$TM add-debater security-review monitor-bot --role "ops engineer focused on deployment risks"

# 3. Start initial round
$TM round security-review start
# ğŸ—£ï¸  Debate Round 1 (initial) started
# Outputs dispatch prompts for each debater

# 4. Collect initial positions
$TM round security-review collect code-agent  "Found SQL injection in login()"
$TM round security-review collect test-agent  "Missing input validation on email field"
$TM round security-review collect monitor-bot "No rate limiting on auth endpoints"
# âœ… Round 1 (initial) is complete.
# â¡ï¸  Next: round security-review cross-review

# 5. Generate cross-review prompts
$TM round security-review cross-review
# ğŸ” Each debater gets others' positions + review instructions

# 6. Collect cross-reviews
$TM round security-review collect code-agent  "Agree on validation. Rate limiting is critical."
$TM round security-review collect test-agent  "SQL injection is most severe. Adding rate limit tests."
$TM round security-review collect monitor-bot "Both findings valid. Recommending WAF as additional layer."

# 7. Synthesize all positions
$TM round security-review synthesize
# ğŸ§¾ Outputs all initial positions + cross-reviews for final synthesis
```

**Debate workflow diagram:**
```
Question â†’ [Agent A] â†’ Position A â”€â”
         â†’ [Agent B] â†’ Position B â”€â”¤â”€â”€ Cross-Review â”€â”€ Synthesis
         â†’ [Agent C] â†’ Position C â”€â”˜
```

## CLI Reference

### All Commands

| Command | Mode | Usage | Description |
|---------|------|-------|-------------|
| `init` | all | `init <project> -g "goal" [-m linear\|dag\|debate]` | Create project |
| `add` | dag | `add <project> <task-id> -a <agent> -d <deps>` | Add task with deps |
| `add-debater` | debate | `add-debater <project> <agent-id> [-r "role"]` | Add debater |
| `round` | debate | `round <project> start\|collect\|cross-review\|synthesize` | Debate actions |
| `status` | all | `status <project> [--json]` | Show progress |
| `assign` | linear/dag | `assign <project> <stage> "desc"` | Set task description |
| `update` | linear/dag | `update <project> <stage> <status>` | Change status |
| `next` | linear | `next <project> [--json]` | Get next stage |
| `ready` | dag | `ready <project> [--json]` | Get dispatchable tasks |
| `graph` | dag | `graph <project>` | Show dependency tree |
| `log` | linear/dag | `log <project> <stage> "msg"` | Add log entry |
| `result` | linear/dag | `result <project> <stage> "output"` | Save stage output |
| `reset` | linear/dag | `reset <project> [stage] [--all]` | Reset to pending |
| `history` | linear/dag | `history <project> <stage>` | Show log history |
| `list` | all | `list` | List all projects |

### Status Values

| Status | Icon | Meaning |
|--------|------|---------|
| `pending` | â¬œ | Waiting for dispatch |
| `in-progress` | ğŸ”„ | Agent is working |
| `done` | âœ… | Completed |
| `failed` | âŒ | Failed (pipeline blocks downstream) |
| `skipped` | â­ï¸ | Intentionally skipped |

### Init Options

```bash
python3 scripts/task_manager.py init <project> \
  --goal "Project description" \
  --mode linear|dag|debate \
  --pipeline "agent1,agent2,agent3"  # linear only \
  --workspace "/path/to/shared/dir" \
  --force  # overwrite existing
```

## Integration with OpenClaw

This tool is designed as an [OpenClaw Skill](https://docs.openclaw.ai). The orchestrating agent (AGI) dispatches tasks to worker agents via `sessions_send` and tracks state through the CLI.

**Dispatch loop (linear):**
```
1. next <project> --json           â†’ get next stage info
2. update <project> <agent> in-progress
3. sessions_send(agent, task)      â†’ dispatch to agent
4. Wait for agent reply
5. result <project> <agent> "..."  â†’ save output
6. update <project> <agent> done   â†’ auto-advances to next stage
7. Repeat
```

**Dispatch loop (DAG):**
```
1. ready <project> --json          â†’ get ALL dispatchable tasks
2. For each ready task (parallel):
   a. update <project> <task> in-progress
   b. sessions_send(agent, task + depOutputs)
3. On reply: result â†’ update done â†’ check newly unblocked
4. Repeat until all tasks complete
```

## Common Pitfalls

### âš ï¸ Linear mode: Stage ID = agent name, NOT a number

```bash
# âŒ WRONG â€” "stage '1' not found"
python3 scripts/task_manager.py assign my-project 1 "Build API"

# âœ… CORRECT
python3 scripts/task_manager.py assign my-project code-agent "Build API"
```

### âš ï¸ DAG: Dependencies must exist before referencing

```bash
# âŒ WRONG â€” "dependency 'design' not found"
$TM add my-project implement -a code-agent -d "design"

# âœ… CORRECT â€” add deps first
$TM add my-project design -a docs-agent --desc "Write spec"
$TM add my-project implement -a code-agent -d "design" --desc "Implement"
```

### âš ï¸ Debate: Cannot add debaters after rounds start

```bash
# âŒ WRONG
$TM round my-debate start
$TM add-debater my-debate new-agent  # Error!

# âœ… CORRECT â€” add all debaters before starting
$TM add-debater my-debate agent-a
$TM add-debater my-debate agent-b
$TM round my-debate start
```

## Data Storage

Project files are stored as JSON at:
```
/home/ubuntu/clawd/data/team-tasks/<project>.json
```

Override with environment variable:
```bash
export TEAM_TASKS_DIR=/custom/path
```

## Project Structure

```
team-tasks/
â”œâ”€â”€ README.md              # This file
â”œâ”€â”€ SKILL.md               # OpenClaw skill definition
â”œâ”€â”€ SPEC.md                # Enhancement spec (debate + workspace)
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ task_manager.py    # Main CLI tool (Python 3.12+, stdlib only)
â””â”€â”€ docs/
    â”œâ”€â”€ GAP_ANALYSIS.md    # Comparison with Claude Code Agent Teams
    â””â”€â”€ AGENT_TEAMS_OFFICIAL_DOCS.md  # Reference documentation
```

## License

MIT
